{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1262ebe-370f-4a61-8c06-30f9c3ce2e12",
   "metadata": {},
   "source": [
    "SPARK: TIME ANALYSIS"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4dcd05ca-92aa-4bf3-a7c3-be5737ed874f",
   "metadata": {},
   "source": [
    "Description\n",
    "3 studies on the data provided in the file tripdata_2017_01.csv\n",
    "    1. Average speed of taxis in terms of the hour\n",
    "    2. Most common taxi trips\n",
    "    3. Financial records (tips, persons, etc)\n",
    "We are going to use Spark's API (RDDs), dataframes and direct SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e51f7a1b-5991-431d-9c26-c5354a92c224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
      "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09ae07dd-090c-49b1-90d7-31d88f80dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#we are going to crate a SparkSession with the name \"lab_spark\"\n",
    "spark = SparkSession.builder.appName(\"lab_spark\").getOrCreate()\n",
    "\n",
    "#obtain the SparkContext from the SparkSession\n",
    "spark_context = spark.sparkContext\n",
    "\n",
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "#import pickle\n",
    "\n",
    "#import functions and classes from pyspark.sql\n",
    "from pyspark.sql.functions import col, round, expr, from_unixtime, unix_timestamp, date_format #module to work with columns\n",
    "from pyspark.sql.types import IntegerType #module to work with integer data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f37bd62-a40b-45c4-97f2-c46f211f55a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to calculate the time it takes to read the data\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91654b4f-94bf-40dc-bfff-ee1d5e47f71f",
   "metadata": {},
   "source": [
    "Now, we are going to read the dataset of the taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32471550-0e37-464d-8e3e-fd7a022ae020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|       1| 2017-01-09 11:13:28|  2017-01-09 11:25:45|              1|          3.3|         1|                 N|         263|         161|           1|       12.5|  0.0|    0.5|       2.0|         0.0|                  0.3|        15.3|\n",
      "|       1| 2017-01-09 11:32:27|  2017-01-09 11:36:01|              1|          0.9|         1|                 N|         186|         234|           1|        5.0|  0.0|    0.5|      1.45|         0.0|                  0.3|        7.25|\n",
      "|       1| 2017-01-09 11:38:20|  2017-01-09 11:42:05|              1|          1.1|         1|                 N|         164|         161|           1|        5.5|  0.0|    0.5|       1.0|         0.0|                  0.3|         7.3|\n",
      "|       1| 2017-01-09 11:52:13|  2017-01-09 11:57:36|              1|          1.1|         1|                 N|         236|          75|           1|        6.0|  0.0|    0.5|       1.7|         0.0|                  0.3|         8.5|\n",
      "|       2| 2017-01-01 00:00:00|  2017-01-01 00:00:00|              1|         0.02|         2|                 N|         249|         234|           2|       52.0|  0.0|    0.5|       0.0|         0.0|                  0.3|        52.8|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_data_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"timestampFormat\", \"yyyy-MM-dd HH:mm:ss\").option(\"mode\", \"PERMISSIVE\").load(r\"./tripdata_2017_01.csv\") \n",
    "taxi_data_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7cc4a26-c13c-4071-91db-ce2aa7920a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "time_to_read=(end_time - start_time)#time it takes to read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "851158ab-bbf8-4718-aeda-770784eb241d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to read the data with Spark dataframes:  65.47151589393616\n"
     ]
    }
   ],
   "source": [
    "print('Time it takes to read the data with Spark dataframes: ', time_to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96250cae-e3ca-4ff9-b2c4-4b55bdb74c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taxi_data_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a14585-e0ce-4c16-8bed-bf707f6cdb8e",
   "metadata": {},
   "source": [
    "Now, let's clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f34143f8-392b-4a82-8c4f-7dddc45fe47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to calculate the time it takes to clean the data\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d326cc0f-f43c-4a9b-b5dc-c098890dc44b",
   "metadata": {},
   "source": [
    "We are going to calculate the total duration of each trip and remove the ones that have a duration of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03db2026-f607-41de-abba-ecec229ac32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data_df = taxi_data_df.withColumn(\"trip_time_hours\", round((unix_timestamp(col(\"tpep_dropoff_datetime\")) - unix_timestamp(col(\"tpep_pickup_datetime\"))) / 3600, 2)) #calculate the trip time in hours\n",
    "taxi_data_df = taxi_data_df.filter(col('trip_time_hours') >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63545e1-d147-4f91-ba68-188c8c1399c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's count how many of them do we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ceeed06f-245e-49df-bfac-a7ae4c52eac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "965985"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35ba441-90e5-4254-be7b-0c128a0d24b0",
   "metadata": {},
   "source": [
    "We are going to remove rows <=0 (tip_amount, total_amount, fare_amount, mta_tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9ce8eac-5489-486c-9607-91a59b4f674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter values of tips and other taxes lower than 0\n",
    "\n",
    "#for column in [\"tip_amount\", \"tolls_amount\", \"improvement_surcharge\", \"total_amount\"]:\n",
    "    #taxi_data_df = taxi_data_df.filter(col(column) >= 0)\n",
    "#¡¡¡¡¡¡¡¡DUDA DE SI total_amount Y fare_amount SOLO DESCARTAR LOS >0 Y DEJAR LOS =0!!!!!!!!!!!!!!!!!\n",
    "\n",
    "for column in ['tip_amount', 'mta_tax']:\n",
    "    taxi_data_df = taxi_data_df.filter(taxi_data_df[column] >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f55f9753-e4af-4525-8919-9626710c01e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['fare_amount', 'total_amount']:\n",
    "        taxi_data_df = taxi_data_df.filter(taxi_data_df[column] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9302701-50ef-430e-9420-f9d5829136a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "965794"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e88ff9-0398-44be-b6e5-7fff66653319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
